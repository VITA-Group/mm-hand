import os
import pickle
import random
import sys

import cv2
import numpy as np
import torch
from easydict import EasyDict as edict
from torch.utils.data import DataLoader
from torch.utils.data import Dataset
from .generic_dataset import Genericdataset



class RHDdataset(Genericdataset):
    def __init__(self, opt):
        """ RHD dataset for dataset processed by create_RHD_DP.py
        :param path: path to dataset (assuming this is the file folder generated by create_MHP_DB.py
        :param mode: paired (depthmap and rgb) or unpaired (rgb and random depth) or heatmap
        :param kwargs:
        """
        super().__init__(opt)

        self.color_images = []
        self.depth_images = []
        self.mask_images = []
        for folder in self.annotations.keys():
            for image in self.annotations[folder].keys():
                img_path = os.path.join(self.root_dir, folder, image)
                attr = getattr(self, "{}_images".format(folder))
                attr.append(img_path)

        def sort_priority(x):
            *_, folder, name = x.split('/')
            name = int(name[0:-4])
            return name

        self.split_ratio = self.opt.augmentation_ratio


        self.image_source, self.image_target = self._get_src_tgt(self.split_ratio,
                                                                 self.color_images, sort_priority)


class _RHDdataset(Dataset):
    def __init__(self, opt):
        """ RHD dataset for dataset processed by create_RHD_DP.py
        :param path: path to dataset (assuming this is the file folder generated by create_MHP_DB.py
        :param mode: paired (depthmap and rgb) or unpaired (rgb and random depth) or heatmap
        :param kwargs:
        """
        super().__init__()
        self.opt = opt
        self.root_dir = self.opt.dataroot
        with open(os.path.join(self.root_dir, "annotation.pickle"),
                  "rb") as handle:
            self.annotations = pickle.load(handle)

        self.color_images = []
        self.depth_images = []
        self.mask_images = []
        for folder in self.annotations.keys():
            for image in self.annotations[folder].keys():
                img_path = os.path.join(self.root_dir, folder, image)
                attr = getattr(self, "{}_images".format(folder))
                attr.append(img_path)

        def sort_priority(x):
            *_, folder, name = x.split('/')
            name = int(name[0:-4])
            return name

        self.color_images.sort(key=lambda x: sort_priority(x))

        if self.opt.isTrain:
            self.augmentation_map = np.zeros(self.__len__(), dtype=np.bool)

            n = int((1 - self.opt.augmentation_ratio) *
                    self.__len__())  # number of augmented image
            if self.opt.dataset_mode == 'generate':
                self.augmentation_map[0:int(n)] = True
            else:
                self.augmentation_map[int(n)::] = True
                print(f"train on {np.sum(self.augmentation_map)} images")

            self.color_images = [
                self.color_images[i]
                for i, state in enumerate(self.augmentation_map) if state
            ]
        self.image_color_pair = self.color_images.copy()
        random.shuffle(self.image_color_pair)

    def __len__(self):
        return len(self.color_images)

    def __getitem__(self, item):
        return self.get_item(item)

    def get_item(self, item):
        h_1 = self.image_color_pair[item]
        h_2 = self.color_images[item]

        h1_annos = self.get_labels(h_1)
        h2_annos = self.get_labels(h_2)

        h1_img = self.make_tensor(
            self.normalize(cv2.cvtColor(cv2.imread(h_1), cv2.COLOR_BGR2RGB)))
        h2_img = self.make_tensor(
            self.normalize(cv2.cvtColor(cv2.imread(h_2), cv2.COLOR_BGR2RGB)))

        h1_map = self.get_heatmaps(h1_annos['uv_coord'], h1_img.shape[1::], 6)
        h2_map = self.get_heatmaps(h2_annos['uv_coord'], h2_img.shape[1::], 6)

        h1_depth = cv2.imread(h_1.replace("color", "depth"))
        h2_depth = cv2.imread(h_2.replace("color", "depth"))

        h1_depth = torch.tensor(256.0 * h1_depth[:, :, 2] + h1_depth[:, :, 1])
        # depth = 256 * r + g
        h2_depth = torch.tensor(256.0 * h2_depth[:, :, 2] + h2_depth[:, :, 1])

        h1_depth = ((torch.stack([h1_depth, h1_depth, h1_depth]) /
                     (2**16 - 1)) - 0.5) / 0.5
        # simulate rgb image
        h2_depth = ((torch.stack([h2_depth, h2_depth, h2_depth]) /
                     (2**16 - 1)) - 0.5) / 0.5

        h1_uv = np.array(h1_annos['uv_coord'])
        h1_z = np.expand_dims(np.array(h1_annos['depth']), -1) / 5 * 255
        h1_xyz = torch.tensor(np.concatenate([h1_uv, h1_z], axis=-1))

        h2_uv = np.array(h2_annos['uv_coord'])
        h2_z = np.expand_dims(np.array(h2_annos['depth']), -1) / 5 * 225
        h2_xyz = torch.tensor(np.concatenate([h2_uv, h2_z], axis=-1))

        batch = {}
        batch['H1'] = h1_img
        batch['H2'] = h2_img
        batch['P1'] = h1_map
        batch['P2'] = h2_map
        batch['D1'] = h1_depth
        batch['D2'] = h2_depth
        batch['C1'] = h1_xyz
        batch['C2'] = h2_xyz
        batch['H1_path'] = h_1
        batch['H2_path'] = h_2
        return batch

    @staticmethod
    def normalize(img):
        """normalize image range  [0-255] to [-1, 1] """
        return ((img / 255.0) - 0.5) / 0.5

    @staticmethod
    def make_tensor(img):
        return torch.tensor(img).permute(2, 0, 1).float()

    def get_heatmaps(self, uv_coords, shape, sigma):
        heatmaps = []
        for x, y in uv_coords:
            heatmaps.append(
                torch.tensor(
                    self.gen_heatmap(x, y, shape, sigma).astype(np.float32)))
        heatmaps = torch.stack(heatmaps)
        heatmaps = heatmaps.squeeze(1)
        return heatmaps

    def get_labels(self, image_path):
        *_, folder, name = image_path.split('/')
        return self.annotations[folder][name]

    def gen_heatmap(self, x, y, shape, sigma):
        # base on DGGAN description
        # a heat map is a dirac-delta function on (x,y) with Gaussian Distribution sprinkle on top.
        centermap = np.zeros((shape[0], shape[1], 1), dtype=np.float32)
        center_map = self.gaussian_kernel(shape[0], shape[1], x, y, sigma)
        center_map[center_map > 1] = 1
        center_map[center_map < 0.0099] = 0
        centermap[:, :, 0] = center_map
        return center_map

    @staticmethod
    def draw(image, uv_coord, bbox=None):
        """
        draw image with uv_coord and an optional bounding box
        :param image:
        :param uv_coord:
        :param bbox:
        :return: image
        """
        for i, p in enumerate(uv_coord):
            x, y = p
            cv2.circle(image, (int(x), int(y)), 2, 255, 1)
            cv2.putText(image, str(i), (int(x), int(y)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, 255)
        if bbox is not None:
            cv2.rectangle(image, (bbox[0], bbox[3]), (bbox[1], bbox[2]), 255,
                          2)
        return image

    @staticmethod
    def gaussian_kernel(width, height, x, y, sigma):
        # print(width, height, x, y, sigma)
        gridy, gridx = np.mgrid[0:height, 0:width]
        D2 = (gridx - x)**2 + (gridy - y)**2
        return np.exp(-D2 / 2.0 / sigma / sigma)


if __name__ == "__main__":
    ## testing

    opt = edict()
    opt.dataroot = "./datasets/rhd_dataset/train"
    opt.isTrain = True
    opt.dataset_mode = 'nothpm'
    opt.augmentation_ratio = 0.8
    opt.augmentation_method = "GEN"

    dataset = RHDdataset(opt)
    sample = dataset[0]
    print(len(dataset))
